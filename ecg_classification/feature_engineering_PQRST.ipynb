{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91e91954-e058-44bd-8b7a-a6c74c6103d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "import biosppy.signals.ecg as ecg\n",
    "import neurokit2 as nk\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77c3d518-1956-44d9-b983-abe6809e9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import ---------------------------------------------------------------------------------------------------\n",
    "y_train_raw = pd.read_csv('data/y_train.csv', index_col='id')\n",
    "X_train_raw = pd.read_csv('data/X_train.csv', index_col='id')\n",
    "X_test_raw = pd.read_csv(\"data/X_test.csv\", index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdbc31d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION DEFINITIONS ------------------------------------------------------------------------------------------\n",
    "\n",
    "# loop over rows and extract features from single observations --------------------------------------------------\n",
    "def generate_features(X):\n",
    "    \n",
    "    X_features = []\n",
    "    \n",
    "    # loop over the rows\n",
    "    for row_idx in range(X.shape[0]): \n",
    "        \n",
    "        # show progress\n",
    "        if (row_idx % 100) == 0:\n",
    "            print(round(row_idx/X.shape[0] * 100, 1), \"% completed\")\n",
    "            \n",
    "        # compute the features\n",
    "        rpeaks_features = compute_rpeaks_features(X.iloc[row_idx])\n",
    "        PQST_features = compute_PQST_features(X.iloc[row_idx])\n",
    "        \n",
    "        # merge the features and add index\n",
    "        features_single_obs = pd.concat([rpeaks_features, PQST_features], axis=1)\n",
    "        df_id = pd.DataFrame({\"id\": [row_idx]})\n",
    "        X_features.append(pd.concat([df_id, features_single_obs], axis=1))\n",
    "    \n",
    "    X_features = pd.concat(X_features)\n",
    "    X_features.replace([np.inf, -np.inf], np.nan, inplace=True) # (some values are inf, -inf)\n",
    "    X_features.set_index('id', inplace=True)\n",
    "            \n",
    "    return X_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute R-peaks-related features of a single signal ------------------------------------------------------------\n",
    "def compute_rpeaks_features(ecg_signal):\n",
    "    \n",
    "    colnames_all = ['R_amplitude_mean', 'R_amplitude_std', 'R_amplitude_min',\n",
    "                'R_amplitude_25%', 'R_amplitude_50%', 'R_amplitude_75%',\n",
    "                'R_amplitude_max', 'R_ECG_Rate_Mean', 'R_HRV_MeanNN', 'R_HRV_SDNN',\n",
    "                'R_HRV_SDANN1', 'R_HRV_SDNNI1', 'R_HRV_SDANN2', 'R_HRV_SDNNI2',\n",
    "                'R_HRV_SDANN5', 'R_HRV_SDNNI5', 'R_HRV_RMSSD', 'R_HRV_SDSD',\n",
    "                'R_HRV_CVNN', 'R_HRV_CVSD', 'R_HRV_MedianNN', 'R_HRV_MadNN',\n",
    "                'R_HRV_MCVNN', 'R_HRV_IQRNN', 'R_HRV_Prc20NN', 'R_HRV_Prc80NN',\n",
    "                'R_HRV_pNN50', 'R_HRV_pNN20', 'R_HRV_MinNN', 'R_HRV_MaxNN', 'R_HRV_HTI',\n",
    "                'R_HRV_TINN', 'R_HRV_ULF', 'R_HRV_VLF', 'R_HRV_LF', 'R_HRV_HF',\n",
    "                'R_HRV_VHF', 'R_HRV_LFHF', 'R_HRV_LFn', 'R_HRV_HFn', 'R_HRV_LnHF',\n",
    "                'R_HRV_SD1', 'R_HRV_SD2', 'R_HRV_SD1SD2', 'R_HRV_S', 'R_HRV_CSI',\n",
    "                'R_HRV_CVI', 'R_HRV_CSI_Modified', 'R_HRV_PIP', 'R_HRV_IALS',\n",
    "                'R_HRV_PSS', 'R_HRV_PAS', 'R_HRV_GI', 'R_HRV_SI', 'R_HRV_AI',\n",
    "                'R_HRV_PI', 'R_HRV_C1d', 'R_HRV_C1a', 'R_HRV_SD1d', 'R_HRV_SD1a',\n",
    "                'R_HRV_C2d', 'R_HRV_C2a', 'R_HRV_SD2d', 'R_HRV_SD2a', 'R_HRV_Cd',\n",
    "                'R_HRV_Ca', 'R_HRV_SDNNd', 'R_HRV_SDNNa', 'R_HRV_DFA_alpha1',\n",
    "                'R_HRV_MFDFA_alpha1_Width', 'R_HRV_MFDFA_alpha1_Peak',\n",
    "                'R_HRV_MFDFA_alpha1_Mean', 'R_HRV_MFDFA_alpha1_Max',\n",
    "                'R_HRV_MFDFA_alpha1_Delta', 'R_HRV_MFDFA_alpha1_Asymmetry',\n",
    "                'R_HRV_MFDFA_alpha1_Fluctuation', 'R_HRV_MFDFA_alpha1_Increment',\n",
    "                'R_HRV_ApEn', 'R_HRV_SampEn', 'R_HRV_ShanEn', 'R_HRV_FuzzyEn',\n",
    "                'R_HRV_MSEn', 'R_HRV_CMSEn', 'R_HRV_RCMSEn', 'R_HRV_CD', 'R_HRV_HFD',\n",
    "                'R_HRV_KFD', 'R_HRV_LZC']\n",
    "    \n",
    "    colnames_amplitude = ['R_amplitude_mean', 'R_amplitude_std', 'R_amplitude_min',\n",
    "                'R_amplitude_25%', 'R_amplitude_50%', 'R_amplitude_75%',\n",
    "                'R_amplitude_max']\n",
    "    \n",
    "    colnames_hrv = ['R_ECG_Rate_Mean', 'R_HRV_MeanNN', 'R_HRV_SDNN', 'R_HRV_SDANN1',\n",
    "                'R_HRV_SDNNI1', 'R_HRV_SDANN2', 'R_HRV_SDNNI2', 'R_HRV_SDANN5',\n",
    "                'R_HRV_SDNNI5', 'R_HRV_RMSSD', 'R_HRV_SDSD', 'R_HRV_CVNN', 'R_HRV_CVSD',\n",
    "                'R_HRV_MedianNN', 'R_HRV_MadNN', 'R_HRV_MCVNN', 'R_HRV_IQRNN',\n",
    "                'R_HRV_Prc20NN', 'R_HRV_Prc80NN', 'R_HRV_pNN50', 'R_HRV_pNN20',\n",
    "                'R_HRV_MinNN', 'R_HRV_MaxNN', 'R_HRV_HTI', 'R_HRV_TINN', 'R_HRV_ULF',\n",
    "                'R_HRV_VLF', 'R_HRV_LF', 'R_HRV_HF', 'R_HRV_VHF', 'R_HRV_LFHF',\n",
    "                'R_HRV_LFn', 'R_HRV_HFn', 'R_HRV_LnHF', 'R_HRV_SD1', 'R_HRV_SD2',\n",
    "                'R_HRV_SD1SD2', 'R_HRV_S', 'R_HRV_CSI', 'R_HRV_CVI',\n",
    "                'R_HRV_CSI_Modified', 'R_HRV_PIP', 'R_HRV_IALS', 'R_HRV_PSS',\n",
    "                'R_HRV_PAS', 'R_HRV_GI', 'R_HRV_SI', 'R_HRV_AI', 'R_HRV_PI',\n",
    "                'R_HRV_C1d', 'R_HRV_C1a', 'R_HRV_SD1d', 'R_HRV_SD1a', 'R_HRV_C2d',\n",
    "                'R_HRV_C2a', 'R_HRV_SD2d', 'R_HRV_SD2a', 'R_HRV_Cd', 'R_HRV_Ca',\n",
    "                'R_HRV_SDNNd', 'R_HRV_SDNNa', 'R_HRV_DFA_alpha1',\n",
    "                'R_HRV_MFDFA_alpha1_Width', 'R_HRV_MFDFA_alpha1_Peak',\n",
    "                'R_HRV_MFDFA_alpha1_Mean', 'R_HRV_MFDFA_alpha1_Max',\n",
    "                'R_HRV_MFDFA_alpha1_Delta', 'R_HRV_MFDFA_alpha1_Asymmetry',\n",
    "                'R_HRV_MFDFA_alpha1_Fluctuation', 'R_HRV_MFDFA_alpha1_Increment',\n",
    "                'R_HRV_ApEn', 'R_HRV_SampEn', 'R_HRV_ShanEn', 'R_HRV_FuzzyEn',\n",
    "                'R_HRV_MSEn', 'R_HRV_CMSEn', 'R_HRV_RCMSEn', 'R_HRV_CD', 'R_HRV_HFD',\n",
    "                'R_HRV_KFD', 'R_HRV_LZC']\n",
    "             \n",
    "    # cut the trailing NAs\n",
    "    ecg_signal = ecg_signal.dropna().to_numpy(dtype='float32')\n",
    "\n",
    "    # inversion of flipped signals\n",
    "    ecg_signal, _ = nk.ecg_invert(ecg_signal, sampling_rate=300, force=False, show=False)\n",
    "    ecg_signal = pd.Series(ecg_signal)\n",
    "    \n",
    "    try:\n",
    "        # compute R peaks\n",
    "        clean_ecg_signal = nk.ecg_clean(ecg_signal, sampling_rate=300)\n",
    "        _, rpeaks = nk.ecg_peaks(ecg_signal, sampling_rate=300)\n",
    "        \n",
    "        try:\n",
    "            # compute amplitude-related features\n",
    "            clean_ecg_signal = pd.Series(clean_ecg_signal)\n",
    "            peak_amplitudes = clean_ecg_signal[ pd.Series(rpeaks['ECG_R_Peaks']).dropna().astype(int) ] # remove invalid peak locations 'nan'\n",
    "            amplitude_features = pd.DataFrame(peak_amplitudes.describe()[1:]).transpose() # summary statistics except counts=#records\n",
    "            amplitude_features.columns = 'R' + '_amplitude_' + amplitude_features.columns\n",
    "        except:\n",
    "            # compute vector of nan with same length and same name\n",
    "            amplitude_features = pd.DataFrame(np.nan, index=[0], columns=colnames_amplitude)\n",
    "        \n",
    "        try:\n",
    "            # compute ALL the available HRV features \n",
    "            processed_data, _ = nk.bio_process(ecg=ecg_signal, sampling_rate=300)\n",
    "            rpeaks_features = nk.bio_analyze(processed_data, sampling_rate=300, method='interval-related')\n",
    "            rpeaks_features.columns = 'R_' + rpeaks_features.columns\n",
    "        except:\n",
    "            # compute vector of nan with same length and same name\n",
    "            rpeaks_features = pd.DataFrame(np.nan, index=[0], columns=colnames_hrv)\n",
    "            \n",
    "        # combine the computed features\n",
    "        features = pd.concat([amplitude_features, rpeaks_features], axis=1)\n",
    "        \n",
    "    except:\n",
    "        # compute vector of nan with same length and same name\n",
    "        features = pd.DataFrame(np.nan, index=[0], columns=colnames_all)\n",
    "        \n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute the features related to the other kind of peaks ----------------------------------------------------------\n",
    "def compute_PQST_features(ecg_signal):\n",
    "    \n",
    "    colnames = ['P_HRV_MeanNN','P_HRV_SDNN','P_HRV_SDANN1','P_HRV_SDNNI1','P_HRV_SDANN2','P_HRV_SDNNI2','P_HRV_SDANN5','P_HRV_SDNNI5'\n",
    "                ,'P_HRV_RMSSD','P_HRV_SDSD','P_HRV_CVNN','P_HRV_CVSD','P_HRV_MedianNN','P_HRV_MadNN','P_HRV_MCVNN','P_HRV_IQRNN','P_HRV_Prc20NN','P_HRV_Prc80NN','P_HRV_pNN50'\n",
    "                ,'P_HRV_pNN20','P_HRV_MinNN','P_HRV_MaxNN','P_HRV_HTI','P_HRV_TINN','P_amplitude_mean','P_amplitude_std','P_amplitude_min','P_amplitude_25%','P_amplitude_50%','P_amplitude_75%','P_amplitude_max'\n",
    "                ,'Q_HRV_MeanNN','Q_HRV_SDNN','Q_HRV_SDANN1','Q_HRV_SDNNI1','Q_HRV_SDANN2','Q_HRV_SDNNI2','Q_HRV_SDANN5','Q_HRV_SDNNI5','Q_HRV_RMSSD'\n",
    "                ,'Q_HRV_SDSD','Q_HRV_CVNN','Q_HRV_CVSD','Q_HRV_MedianNN','Q_HRV_MadNN','Q_HRV_MCVNN','Q_HRV_IQRNN','Q_HRV_Prc20NN','Q_HRV_Prc80NN'\n",
    "                ,'Q_HRV_pNN50','Q_HRV_pNN20','Q_HRV_MinNN','Q_HRV_MaxNN','Q_HRV_HTI','Q_HRV_TINN','Q_amplitude_mean','Q_amplitude_std','Q_amplitude_min'\n",
    "                ,'Q_amplitude_25%','Q_amplitude_50%','Q_amplitude_75%','Q_amplitude_max','S_HRV_MeanNN','S_HRV_SDNN','S_HRV_SDANN1','S_HRV_SDNNI1'\n",
    "                ,'S_HRV_SDANN2','S_HRV_SDNNI2','S_HRV_SDANN5','S_HRV_SDNNI5','S_HRV_RMSSD','S_HRV_SDSD','S_HRV_CVNN','S_HRV_CVSD','S_HRV_MedianNN'\n",
    "                ,'S_HRV_MadNN','S_HRV_MCVNN','S_HRV_IQRNN','S_HRV_Prc20NN','S_HRV_Prc80NN','S_HRV_pNN50','S_HRV_pNN20','S_HRV_MinNN','S_HRV_MaxNN','S_HRV_HTI','S_HRV_TINN'\n",
    "                ,'S_amplitude_mean','S_amplitude_std','S_amplitude_min','S_amplitude_25%','S_amplitude_50%','S_amplitude_75%','S_amplitude_max','T_HRV_MeanNN','T_HRV_SDNN','T_HRV_SDANN1'\n",
    "                ,'T_HRV_SDNNI1','T_HRV_SDANN2','T_HRV_SDNNI2','T_HRV_SDANN5','T_HRV_SDNNI5','T_HRV_RMSSD','T_HRV_SDSD','T_HRV_CVNN','T_HRV_CVSD','T_HRV_MedianNN','T_HRV_MadNN','T_HRV_MCVNN'\n",
    "                ,'T_HRV_IQRNN','T_HRV_Prc20NN','T_HRV_Prc80NN','T_HRV_pNN50','T_HRV_pNN20','T_HRV_MinNN','T_HRV_MaxNN','T_HRV_HTI','T_HRV_TINN','T_amplitude_mean','T_amplitude_std','T_amplitude_min'\n",
    "                ,'T_amplitude_25%','T_amplitude_50%','T_amplitude_75%','T_amplitude_max','meanQ_Ponset','meanToffset_Q','meanSQ','meanQP','meanTS','stdQ_Ponset','stdToffset_Q'\n",
    "                ,'stdSQ','stdQP','stdTS','minQ_Ponset','minToffset_Q','minSQ','minQP','minTS','25%Q_Ponset','25%Toffset_Q','25%SQ','25%QP'\n",
    "                ,'25%TS' ,'50%Q_Ponset' ,'50%Toffset_Q' ,'50%SQ' ,'50%QP' ,'50%TS' ,'75%Q_Ponset' ,'75%Toffset_Q' ,'75%SQ'\n",
    "                ,'75%QP','75%TS','maxQ_Ponset','maxToffset_Q','maxSQ','maxQP','maxTS']\n",
    "    \n",
    "    # cut the trailing NAs\n",
    "    ecg_signal = ecg_signal.dropna().to_numpy(dtype='float32')\n",
    "    \n",
    "    # inversion of flipped signals\n",
    "    ecg_signal, _ = nk.ecg_invert(ecg_signal, sampling_rate=300, force=False, show=False)\n",
    "    ecg_signal = pd.Series(ecg_signal)\n",
    "    \n",
    "    try:\n",
    "        # compute PQST peaks\n",
    "        ecg_signal = nk.ecg_clean(ecg_signal, sampling_rate=300)\n",
    "        _, rpeaks = nk.ecg_peaks(ecg_signal, sampling_rate=300)\n",
    "        _, waves_peak = nk.ecg_delineate(ecg_signal, rpeaks, sampling_rate=300, method=\"peak\")\n",
    "        \n",
    "        # compute PQST peak related features\n",
    "        PQST_peak_related_features = pd.concat(\n",
    "            [\n",
    "                feature_extractor(waves_peak, ecg_signal, peak_type='P'),\n",
    "                feature_extractor(waves_peak, ecg_signal, peak_type='Q'),\n",
    "                feature_extractor(waves_peak, ecg_signal, peak_type='S'),\n",
    "                feature_extractor(waves_peak, ecg_signal, peak_type='T')\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # compute interval related features\n",
    "        interval_features = compute_interval_features(waves_peak)\n",
    "        \n",
    "        # combine the computed features\n",
    "        features = pd.concat([PQST_peak_related_features, interval_features], axis=1)\n",
    "        \n",
    "    except:\n",
    "        features = pd.DataFrame(np.nan, index=[0], columns=colnames)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute HRV and Amplitude -related features for the other peaks ----------------------------------------------------\n",
    "def feature_extractor(waves_peak, ecg_signal, peak_type):\n",
    "    \"\"\"\n",
    "    peak_type: {P,Q,S,T}\n",
    "    \"\"\"\n",
    "    colnames_hrv_P = ['P_HRV_MeanNN', 'P_HRV_SDNN', 'P_HRV_SDANN1', 'P_HRV_SDNNI1',\n",
    "       'P_HRV_SDANN2', 'P_HRV_SDNNI2', 'P_HRV_SDANN5', 'P_HRV_SDNNI5',\n",
    "       'P_HRV_RMSSD', 'P_HRV_SDSD', 'P_HRV_CVNN', 'P_HRV_CVSD',\n",
    "       'P_HRV_MedianNN', 'P_HRV_MadNN', 'P_HRV_MCVNN', 'P_HRV_IQRNN',\n",
    "       'P_HRV_Prc20NN', 'P_HRV_Prc80NN', 'P_HRV_pNN50', 'P_HRV_pNN20',\n",
    "       'P_HRV_MinNN', 'P_HRV_MaxNN', 'P_HRV_HTI', 'P_HRV_TINN']\n",
    "    colnames_hrv_Q = ['Q_HRV_MeanNN', 'Q_HRV_SDNN', 'Q_HRV_SDANN1', 'Q_HRV_SDNNI1',\n",
    "       'Q_HRV_SDANN2', 'Q_HRV_SDNNI2', 'Q_HRV_SDANN5', 'Q_HRV_SDNNI5',\n",
    "       'Q_HRV_RMSSD', 'Q_HRV_SDSD', 'Q_HRV_CVNN', 'Q_HRV_CVSD',\n",
    "       'Q_HRV_MedianNN', 'Q_HRV_MadNN', 'Q_HRV_MCVNN', 'Q_HRV_IQRNN',\n",
    "       'Q_HRV_Prc20NN', 'Q_HRV_Prc80NN', 'Q_HRV_pNN50', 'Q_HRV_pNN20',\n",
    "       'Q_HRV_MinNN', 'Q_HRV_MaxNN', 'Q_HRV_HTI', 'Q_HRV_TINN']\n",
    "    colnames_hrv_S = ['S_HRV_MeanNN', 'S_HRV_SDNN', 'S_HRV_SDANN1', 'S_HRV_SDNNI1',\n",
    "       'S_HRV_SDANN2', 'S_HRV_SDNNI2', 'S_HRV_SDANN5', 'S_HRV_SDNNI5',\n",
    "       'S_HRV_RMSSD', 'S_HRV_SDSD', 'S_HRV_CVNN', 'S_HRV_CVSD',\n",
    "       'S_HRV_MedianNN', 'S_HRV_MadNN', 'S_HRV_MCVNN', 'S_HRV_IQRNN',\n",
    "       'S_HRV_Prc20NN', 'S_HRV_Prc80NN', 'S_HRV_pNN50', 'S_HRV_pNN20',\n",
    "       'S_HRV_MinNN', 'S_HRV_MaxNN', 'S_HRV_HTI', 'S_HRV_TINN']\n",
    "    colnames_hrv_T = ['T_HRV_MeanNN', 'T_HRV_SDNN', 'T_HRV_SDANN1', 'T_HRV_SDNNI1',\n",
    "       'T_HRV_SDANN2', 'T_HRV_SDNNI2', 'T_HRV_SDANN5', 'T_HRV_SDNNI5',\n",
    "       'T_HRV_RMSSD', 'T_HRV_SDSD', 'T_HRV_CVNN', 'T_HRV_CVSD',\n",
    "       'T_HRV_MedianNN', 'T_HRV_MadNN', 'T_HRV_MCVNN', 'T_HRV_IQRNN',\n",
    "       'T_HRV_Prc20NN', 'T_HRV_Prc80NN', 'T_HRV_pNN50', 'T_HRV_pNN20',\n",
    "       'T_HRV_MinNN', 'T_HRV_MaxNN', 'T_HRV_HTI', 'T_HRV_TINN']\n",
    "\n",
    "    colnames_amplitude_P = ['P_amplitude_mean', 'P_amplitude_std', 'P_amplitude_min',\n",
    "       'P_amplitude_25%', 'P_amplitude_50%', 'P_amplitude_75%',\n",
    "       'P_amplitude_max']\n",
    "    colnames_amplitude_Q = ['Q_amplitude_mean', 'Q_amplitude_std', 'Q_amplitude_min',\n",
    "       'Q_amplitude_25%', 'Q_amplitude_50%', 'Q_amplitude_75%',\n",
    "       'Q_amplitude_max']\n",
    "    colnames_amplitude_S = ['S_amplitude_mean', 'S_amplitude_std', 'S_amplitude_min',\n",
    "       'S_amplitude_25%', 'S_amplitude_50%', 'S_amplitude_75%',\n",
    "       'S_amplitude_max']\n",
    "    colnames_amplitude_T = ['T_amplitude_mean', 'T_amplitude_std', 'T_amplitude_min',\n",
    "       'T_amplitude_25%', 'T_amplitude_50%', 'T_amplitude_75%',\n",
    "       'T_amplitude_max']\n",
    "    \n",
    "    peak_name = 'ECG_' + peak_type + \"_Peaks\"\n",
    "    \n",
    "    # calculate HRV features\n",
    "    try:\n",
    "        peak_locations = {\n",
    "            'ECG_R_Peaks': np.array(waves_peak[peak_name]), # has be to called ECG_R_Peaks that hrv_time() works\n",
    "            'sampling_rate': 300\n",
    "        }\n",
    "        \n",
    "        hrv_features = nk.hrv_time(peak_locations, sampling_rate=300)\n",
    "        hrv_features.columns = peak_type + '_' + hrv_features.columns\n",
    "    except:\n",
    "        match peak_type:\n",
    "            case 'P':\n",
    "                hrv_features = pd.DataFrame(np.nan, index=[0], columns=colnames_hrv_P)\n",
    "            case 'Q':\n",
    "                hrv_features = pd.DataFrame(np.nan, index=[0], columns=colnames_hrv_Q)\n",
    "            case 'S':\n",
    "                hrv_features = pd.DataFrame(np.nan, index=[0], columns=colnames_hrv_S)\n",
    "            case 'T':\n",
    "                hrv_features = pd.DataFrame(np.nan, index=[0], columns=colnames_hrv_T)\n",
    "        \n",
    "    # calculate amplitude features\n",
    "    try:\n",
    "        ecg_signal = pd.Series(ecg_signal)\n",
    "        peak_amplitudes = ecg_signal[pd.Series(waves_peak[peak_name]).dropna().astype(int)] # remove invalid peak locations 'nan'\n",
    "        amplitude_features = pd.DataFrame(peak_amplitudes.describe()[1:]).transpose() # summary statistics except counts=#records\n",
    "        amplitude_features.columns = peak_type + '_amplitude_' + amplitude_features.columns\n",
    "    except:\n",
    "        match peak_type:\n",
    "            case 'P':\n",
    "                hrv_features = pd.DataFrame(np.nan, index=[0], columns=colnames_amplitude_P)\n",
    "            case 'Q':\n",
    "                hrv_features = pd.DataFrame(np.nan, index=[0], columns=colnames_amplitude_Q)\n",
    "            case 'S':\n",
    "                hrv_features = pd.DataFrame(np.nan, index=[0], columns=colnames_amplitude_S)\n",
    "            case 'T':\n",
    "                hrv_features = pd.DataFrame(np.nan, index=[0], columns=colnames_amplitude_T)\n",
    "        \n",
    "    # combine all features\n",
    "    features = pd.concat([hrv_features, amplitude_features], axis=1)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute features for various Intervals --------------------------------------------------------------------------\n",
    "def compute_interval_features(waves_peak):\n",
    "    \n",
    "    colnames = ['meanQ_Ponset', 'meanToffset_Q', 'meanSQ', 'meanQP', 'meanTS',\n",
    "            'stdQ_Ponset', 'stdToffset_Q', 'stdSQ', 'stdQP', 'stdTS', 'minQ_Ponset',\n",
    "            'minToffset_Q', 'minSQ', 'minQP', 'minTS', '25%Q_Ponset',\n",
    "            '25%Toffset_Q', '25%SQ', '25%QP', '25%TS', '50%Q_Ponset',\n",
    "            '50%Toffset_Q', '50%SQ', '50%QP', '50%TS', '75%Q_Ponset',\n",
    "            '75%Toffset_Q', '75%SQ', '75%QP', '75%TS', 'maxQ_Ponset',\n",
    "            'maxToffset_Q', 'maxSQ', 'maxQP', 'maxTS']\n",
    "    \n",
    "    try:\n",
    "        peak_df = pd.DataFrame(waves_peak)\n",
    "        \n",
    "        interval_features = pd.DataFrame()\n",
    "        interval_features['Q_Ponset'] = peak_df['ECG_Q_Peaks'] - peak_df['ECG_P_Onsets']\n",
    "        interval_features['Toffset_Q'] = peak_df['ECG_T_Offsets'] - peak_df['ECG_Q_Peaks']\n",
    "        interval_features['SQ'] = peak_df['ECG_S_Peaks'] - peak_df['ECG_Q_Peaks']\n",
    "    \n",
    "        interval_features['QP'] = peak_df['ECG_Q_Peaks'] - peak_df['ECG_P_Peaks']\n",
    "        interval_features['TS'] = peak_df['ECG_T_Peaks'] - peak_df['ECG_S_Peaks']\n",
    "        \n",
    "        describe_features = interval_features.describe().iloc[1:]\n",
    "        feature_row = pd.DataFrame(describe_features.values.reshape(1,35))\n",
    "    \n",
    "        colnames = []\n",
    "        for i in describe_features.index:\n",
    "            for j in describe_features.columns:\n",
    "                colnames.append(i + j)\n",
    "    \n",
    "        feature_row.columns = colnames\n",
    "    \n",
    "    except:\n",
    "        feature_row = pd.DataFrame(np.nan, index=[0], columns=colnames)\n",
    "    \n",
    "    return feature_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bfeb0ef-babf-4711-87a3-16963f4630a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract features for Training ------------------------------------------------------------------------\n",
    "\n",
    "RECOMPUTE_TRAIN = False\n",
    "\n",
    "if RECOMPUTE_TRAIN:\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # compute features\n",
    "    X_train = generate_features(X_train_raw)\n",
    "    \n",
    "    warnings.resetwarnings()\n",
    "    \n",
    "    # write data\n",
    "    X_train.to_csv(\"data/X_train2_processed.csv\", index_label=False)\n",
    "    \n",
    "else:\n",
    "    # read data \n",
    "    X_train = pd.read_csv(\"data/X_train2_processed.csv\")\n",
    "\n",
    "\n",
    "X_train.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e061560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for Testing ------------------------------------------------------------------------\n",
    "\n",
    "RECOMPUTE_TEST = False\n",
    "\n",
    "if RECOMPUTE_TEST:\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # compute features\n",
    "    X_test = generate_features(X_test_raw)\n",
    "    \n",
    "    warnings.resetwarnings()\n",
    "    \n",
    "    # write data\n",
    "    X_test.to_csv(\"data/X_test2_processed.csv\", index_label=False)\n",
    "    \n",
    "else:\n",
    "    # read data\n",
    "    X_test = pd.read_csv(\"data/X_test2_processed.csv\")\n",
    "\n",
    "X_test.dropna(axis=1, how='all', inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
