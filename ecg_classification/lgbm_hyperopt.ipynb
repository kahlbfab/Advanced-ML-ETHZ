{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9983f8f-5c4d-4073-a2ba-407251318bb5",
      "metadata": {
        "id": "e9983f8f-5c4d-4073-a2ba-407251318bb5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgbm\n",
        "import json\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.impute import KNNImputer, SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe, atpe\n",
        "import hyperopt\n",
        "\n",
        "from seaborn import histplot\n",
        "\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a94dc8b",
      "metadata": {
        "id": "2a94dc8b"
      },
      "source": [
        "## Data Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20c14271",
      "metadata": {
        "id": "20c14271"
      },
      "outputs": [],
      "source": [
        "with open('feature_groups.json') as f:\n",
        "    feature_groups = json.load(f)\n",
        "\n",
        "y_train = pd.read_csv(\"data/y_train.csv\")\n",
        "y_train = y_train['y']\n",
        "\n",
        "X_train = pd.read_csv(\"data/X_train_mega.csv\")\n",
        "X_train = X_train.iloc[:, 1:]\n",
        "X_train = X_train[feature_groups['wavelets'] \n",
        "                  + feature_groups['robust_peaks'] \n",
        "                  + feature_groups['hos_and_sign'] \n",
        "                  + feature_groups['R_features'] \n",
        "                  + feature_groups['PQST_hrv'] \n",
        "                  + feature_groups['intervals']]\n",
        "X_train.dropna(axis=1, how='all', inplace=True)\n",
        "\n",
        "X_test = pd.read_csv(\"data/X_test_mega.csv\")\n",
        "X_test = X_test.iloc[:, 1:]\n",
        "X_test = X_test[feature_groups['wavelets'] \n",
        "                  + feature_groups['robust_peaks'] \n",
        "                  + feature_groups['hos_and_sign'] \n",
        "                  + feature_groups['R_features'] \n",
        "                  + feature_groups['PQST_hrv'] \n",
        "                  + feature_groups['intervals']]\n",
        "X_test.dropna(axis=1, how='all', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93701217-9427-41f7-913c-f5ee1911075c",
      "metadata": {
        "id": "93701217-9427-41f7-913c-f5ee1911075c"
      },
      "source": [
        "#Â Hyperparameter Tuning "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcc49546",
      "metadata": {
        "id": "dcc49546"
      },
      "outputs": [],
      "source": [
        "def get_hyp_results_as_df(trials):\n",
        "    hyp_results = []\n",
        "    for entry in trials.trials:\n",
        "        entry_hyperparam_values = entry['misc']['vals']\n",
        "        entry_hyperparam_values = {key: entry_hyperparam_values[key][0] for key in entry_hyperparam_values} # unpack list (there is always one item)\n",
        "        entry_dict = {**entry['result'], **entry_hyperparam_values} # combine the two dicts\n",
        "        hyp_results.append(entry_dict)\n",
        "    hyp_results = pd.DataFrame(hyp_results).sort_values(by='loss')\n",
        "    return hyp_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d07a70-9e15-434a-8490-4721180fc980",
      "metadata": {
        "id": "b3d07a70-9e15-434a-8490-4721180fc980"
      },
      "outputs": [],
      "source": [
        "space = {\n",
        "    'max_depth': hp.uniform('max_depth',1, 30)\n",
        "    ,'num_leaves': hp.loguniform('num_leaves', 1, 10)\n",
        "    ,'n_estimators': hp.loguniform('n_estimators', 5, 7)\n",
        "    ,'learning_rate': hp.loguniform('learning_rate', -10, -1)\n",
        "    ,'reg_lambda': hp.loguniform('reg_lambda', -8, 3)\n",
        "    ,'subsample': hp.uniform('subsample', 0, 1)\n",
        "}\n",
        "\n",
        "def objective(space):\n",
        "    \n",
        "    params = {        \n",
        "        'max_depth': int(space['max_depth'])\n",
        "        ,'num_leaves': int(space['num_leaves'])\n",
        "        ,'n_estimators': int(space['n_estimators'])\n",
        "        ,'learning_rate': space['learning_rate']\n",
        "        ,'reg_lambda': space['reg_lambda']\n",
        "        ,'subsample': space['subsample']\n",
        "    }\n",
        "    \n",
        "    N_SPLITS = 5\n",
        "    kf_cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True)\n",
        "\n",
        "    scores = np.zeros(N_SPLITS)\n",
        "    for idx, (train_idx, val_idx) in enumerate(kf_cv.split(X_train, y_train)):\n",
        "\n",
        "        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "        lgbm_classifier = lgbm.LGBMClassifier(\n",
        "            **params,\n",
        "            class_weight = {\n",
        "                0: 1.69,\n",
        "                2: 3.47,\n",
        "                1: 11.55,\n",
        "                3: 30.10\n",
        "            },\n",
        "            objective = 'multiclass',\n",
        "            num_class = 4,\n",
        "            max_bin = 100,\n",
        "            subsample_freq = 1, \n",
        "            verbose = -1,\n",
        "            boosting_type = 'dart'\n",
        "        )\n",
        "        \n",
        "        lgbm_classifier.fit(\n",
        "            X_train_fold,\n",
        "            y_train_fold,\n",
        "            verbose = False\n",
        "        )\n",
        "        \n",
        "        preds = lgbm_classifier.predict(X_val_fold)\n",
        "        scores[idx] = f1_score(y_true = y_val_fold, y_pred = preds, average='micro')\n",
        "    \n",
        "    avg_loss = np.mean(scores)\n",
        "    return {'loss': -avg_loss, 'loss_variance': np.var(scores, ddof=1), 'status': STATUS_OK }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0ef0d44-4f27-43b4-bcd0-aa270db9fe1b",
      "metadata": {
        "id": "d0ef0d44-4f27-43b4-bcd0-aa270db9fe1b"
      },
      "outputs": [],
      "source": [
        "trials = Trials()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa6146eb-9a93-42b2-bfbe-23fdce3692bd",
      "metadata": {
        "id": "fa6146eb-9a93-42b2-bfbe-23fdce3692bd"
      },
      "outputs": [],
      "source": [
        "best_hyperparams = fmin(\n",
        "    fn = objective,\n",
        "    space = space,\n",
        "    algo = atpe.suggest, #hyperopt.rand.suggest,\n",
        "    max_evals = 50 \n",
        "    ,trials = trials\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afdea673",
      "metadata": {
        "id": "afdea673"
      },
      "outputs": [],
      "source": [
        "hyp_results = get_hyp_results_as_df(trials)\n",
        "pd.set_option('display.max_rows', 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3f0d011-dad7-441e-845e-16b9b0ddca1b",
      "metadata": {
        "id": "f3f0d011-dad7-441e-845e-16b9b0ddca1b"
      },
      "source": [
        "# Training and Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b170cc0c-8100-491f-affb-494e45a678d1",
      "metadata": {
        "id": "b170cc0c-8100-491f-affb-494e45a678d1"
      },
      "outputs": [],
      "source": [
        "def get_kth_best_hyperparams(hyp_results, k):\n",
        "    \"\"\"\n",
        "    k=0 yields the best model\n",
        "    \"\"\"\n",
        "    hyperparam = dict(hyp_results.iloc[k])\n",
        "    hyperparam.pop('loss')\n",
        "    hyperparam.pop('loss_variance')\n",
        "    hyperparam.pop('status')\n",
        "\n",
        "    fixed_parameters = {\n",
        "        'max_bin': 100,\n",
        "        'subsample_freq': 1,\n",
        "        'boosting_type': 'dart' \n",
        "    }\n",
        "\n",
        "    hyperparam = {**hyperparam, **fixed_parameters}\n",
        "    \n",
        "    # convert to integers\n",
        "    hyperparam['max_depth'] = int(hyperparam['max_depth'])\n",
        "    hyperparam['n_estimators'] = int(hyperparam['n_estimators'])\n",
        "    hyperparam['num_leaves'] = int(hyperparam['num_leaves'])\n",
        "\n",
        "    return hyperparam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58446878-2e77-460c-ade2-a4c566328c62",
      "metadata": {
        "id": "58446878-2e77-460c-ade2-a4c566328c62"
      },
      "outputs": [],
      "source": [
        "K_BEST_MODELS = 5\n",
        "y_pred_matrix = np.zeros((X_test.shape[0], K_BEST_MODELS))\n",
        "for k in range(K_BEST_MODELS):\n",
        "    params = get_kth_best_hyperparams(hyp_results, k)\n",
        "    \n",
        "    lgbm_classifier = lgbm.LGBMClassifier(\n",
        "        **params, \n",
        "        class_weight = {\n",
        "                0: 1.69,\n",
        "                2: 3.47,\n",
        "                1: 11.55,\n",
        "                3: 30.10 \n",
        "        },\n",
        "        objective = 'multiclass',\n",
        "        num_class = 4\n",
        "    )\n",
        "\n",
        "    lgbm_classifier.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    y_test_pred = lgbm_classifier.predict(X_test)\n",
        "    y_pred_matrix[:,k] = y_test_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d321946-ade0-4a8f-b7a2-7e8bb345084f",
      "metadata": {
        "id": "6d321946-ade0-4a8f-b7a2-7e8bb345084f"
      },
      "outputs": [],
      "source": [
        "y_majority = pd.DataFrame(y_pred_matrix).mode(axis=1)[0].astype(int)\n",
        "y_majority = pd.DataFrame({'id':np.arange(0,len(y_majority)), 'y':y_majority})\n",
        "y_majority.to_csv(\"data/predictions.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}