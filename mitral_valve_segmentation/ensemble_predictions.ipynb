{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0piptWqtQHB"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import gzip\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import albumentations as A\n",
        "\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH = \"drive/My Drive/data/aml_task_3\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions --------------\n",
        "def load_zipped_pickle(filename):\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        loaded_object = pickle.load(f)\n",
        "        return loaded_object\n",
        "\n",
        "\n",
        "def save_zipped_pickle(obj, filename):\n",
        "    with gzip.open(filename, 'wb') as f:\n",
        "        pickle.dump(obj, f, 2)\n",
        "\n",
        "\n",
        "def show_side_by_side(video, mask):\n",
        "    fig = plt.figure()\n",
        "    fig.add_subplot(1, 2, 1)\n",
        "    plt.imshow(video)\n",
        "    fig.add_subplot(1, 2, 2)\n",
        "    plt.imshow(mask)"
      ],
      "metadata": {
        "id": "oJgifAQktZnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ensem_pred(predictions):\n",
        "    \"\"\"ensemble predictions from a list of images\"\"\"\n",
        "    ensemble_pred = None\n",
        "    for pred in predictions:\n",
        "        if ensemble_pred is None:\n",
        "            ensemble_pred = torch.clone(pred).float()  # Copy here!!\n",
        "        else:\n",
        "            ensemble_pred += pred.float()\n",
        "    ensemble_pred = ensemble_pred / len(predictions)\n",
        "    return ensemble_pred"
      ],
      "metadata": {
        "id": "JEM0-fo2tTCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_predictions = [load_zipped_pickle(f\"{PATH}/model_{i}.pkl\") for i in range(1,5)]\n",
        "data_test = load_zipped_pickle(\"{}/test.pkl\".format(PATH))\n",
        "\n",
        "submission = []\n",
        "for vid_idx, item in enumerate(data_test):\n",
        "    name = item[\"name\"]\n",
        "    video = item[\"video\"]\n",
        "    shape = video[:, :, 0].shape\n",
        "    resizer = A.Resize(shape[0], shape[1])\n",
        "    predictions = []\n",
        "    for idx in range(video.shape[2]):\n",
        "        # ensemble here\n",
        "        frame_predictions = [pred[vid_idx][idx] for pred in model_predictions]\n",
        "        prediction = ensem_pred(frame_predictions)\n",
        "        prediction = prediction.cpu().detach().numpy().squeeze()\n",
        "        prediction = prediction > 0.3\n",
        "        predictions.append(prediction)\n",
        "    predictions = np.stack(predictions, axis=2)\n",
        "    submission.append({\"name\":name, \"prediction\":predictions})\n",
        "\n",
        "save_zipped_pickle(submission, \"{}/ensemble_prediction.pkl\".format(PATH))"
      ],
      "metadata": {
        "id": "7yvbuTYftS9c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}